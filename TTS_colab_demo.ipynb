{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TTS_demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lingjzhu/probing-TTS-models/blob/master/TTS_colab_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbeNGY_pgI08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, expanduser\n",
        "\n",
        "os.chdir(expanduser(\"~\"))\n",
        "tts_dir = 'probing-TTS-models'\n",
        "if not exists(tts_dir):\n",
        "  ! git clone https://github.com/lingjzhu/$tts_dir\n",
        "  ! cd probing-TTS-models && git checkout && cd -\n",
        "  \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlLC7Q7Us8go",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('probing-TTS-models')\n",
        "\n",
        "if not exists('models'):\n",
        "  os.mkdir('models')\n",
        "os.chdir('models')\n",
        "!pwd\n",
        "\n",
        "# download pre-trained WaveGlow\n",
        "! wget -O waveglow_150k https://www.dropbox.com/s/vdy6aui6dg1ziyn/waveglow_150k?dl=0\n",
        "\n",
        "# download pre-trained Tacotron 2 with BERT embeddings\n",
        "! wget -O tacotron2_bert https://www.dropbox.com/s/bct9u8jimz049lg/tacotron2_bert?dl=0\n",
        "\n",
        "# download pre-trained Tacotron 2\n",
        "! wget -O tacotron2 https://www.dropbox.com/s/dn498owcg9wxcvq/tacotron2?dl=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AojOfE7Eg8sj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! gdown --id 1iNeYFhCBJWeUsIlnW_2K6SMwXkM4gLb_\n",
        "! unzip chinese_wwm_ext_pytorch.zip\n",
        "os.chdir('..')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjpIyqd0IbQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -q torch==1.1.0 torchvision==0.3.0\n",
        "! pip install transformers pypinyin unidecode tensorboardX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-P1xcw7ImQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import IPython.display as ipd\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.append('./waveglow/')\n",
        "import numpy as np\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2\n",
        "from train import load_model\n",
        "from text import text_to_sequence\n",
        "from denoiser import Denoiser\n",
        "from text.cleaners import text_normalize\n",
        "from txt2pinyin import txt2pinyin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDlijBarMP6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_data(data, figsize=(16, 4)):\n",
        "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
        "    for i in range(len(data)):\n",
        "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
        "                       interpolation='none')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Glkq_CDaMSF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = create_hparams()\n",
        "# uncomment the following line if you want to use the original Tacotron 2\n",
        "#hparams.bert = False\n",
        "hparams.sampling_rate = 22050"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pNljCmTMVUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"./models/tacotron2_bert\"\n",
        "model = load_model(hparams)\n",
        "model.load_state_dict(torch.load(checkpoint_path))\n",
        "_ = model.cuda().eval().half()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeND6cc_MXHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specify the path to the pre-trained Waveglow\n",
        "waveglow_path = './models/waveglow_150k'\n",
        "waveglow = torch.load(waveglow_path)\n",
        "waveglow.cuda().eval().half()\n",
        "for k in waveglow.convinv:\n",
        "    k.float()\n",
        "for m in waveglow.modules():\n",
        "    if 'Conv' in str(type(m)):\n",
        "        setattr(m, 'padding_mode', 'zeros')\n",
        "denoiser = Denoiser(waveglow)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjYyZ0n6MZ6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_bert(path):\n",
        "    '''\n",
        "    Load the Chinese Bert model in the specified folder\n",
        "    '''\n",
        "    config_path = os.path.join(path,'bert_config.json')\n",
        "    model_path = os.path.join(path,'pytorch_model.bin')\n",
        "    vocab_path = os.path.join(path, 'vocab.txt')\n",
        "    \n",
        "    \n",
        "    config = transformers.BertConfig.from_pretrained(config_path)\n",
        "    config.output_hidden_states=True\n",
        "    \n",
        "    model = transformers.BertModel.from_pretrained(model_path,config=config)\n",
        "    model.eval()\n",
        "    \n",
        "    tokenizer = transformers.BertTokenizer(vocab_path)\n",
        "    \n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "def extract_embeddings(model,tokenizer,text,upsampling=True):\n",
        "    '''\n",
        "    Extract embeddings from the pre-trained bert model.\n",
        "    Apply upsampling to ensure that embedding length are the same as the phoneme length\n",
        "    '''\n",
        "    \n",
        "    clean_text = text_normalize(text)\n",
        "    pinyin_seq = txt2pinyin(clean_text)\n",
        "    phon_seq = [i for syl in pinyin_seq for i in syl]\n",
        "    \n",
        "    inputs = torch.tensor(tokenizer.encode(clean_text)).unsqueeze(0)\n",
        "    assert inputs[0,0]==101 and inputs[0,-1]==102\n",
        "    outputs = model(inputs)    \n",
        "    h = outputs[0].cpu().detach().numpy()\n",
        "#    del outputs\n",
        "    h = h[:,1:-1,:]\n",
        "    assert h.shape[1] == len(pinyin_seq)\n",
        "\n",
        "    features = [np.tile(h[:,i,:],[1,len(syl),1]) for i,syl in enumerate(pinyin_seq)]\n",
        "    features = np.concatenate(features,axis=1)\n",
        "    \n",
        "    assert features.shape[1] == len(phon_seq)\n",
        "    assert features.shape[2] == 768\n",
        "    assert features.shape[0] == 1\n",
        "    \n",
        "    return torch.tensor(features).cuda().half()\n",
        "\n",
        "if hparams.bert == True:\n",
        "    # specify the path to the BERT folder\n",
        "    bert_path = './models/'\n",
        "    bert, tokenizer= load_bert(bert_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-A9XT6uMpaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"刚出炉的烧鹅，呈现出枣红色的光泽，甘香油润，卤汁丰盈，放在任何的宴席上都是一道味彩出众的主菜。\"\n",
        "sequence = np.array(text_to_sequence(text, ['chinese_cleaners']))[None, :]\n",
        "sequence = torch.autograd.Variable(\n",
        "    torch.from_numpy(sequence)).cuda().long()\n",
        "if hparams.bert == True:\n",
        "    features = extract_embeddings(bert,tokenizer,text)\n",
        "    sequence = (sequence, features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2BTFTQXMv5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
        "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
        "           alignments.float().data.cpu().numpy()[0].T))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwU5_BerM_ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    audio = waveglow.infer(mel_outputs_postnet, sigma=0.666)\n",
        "\n",
        "ipd.Audio(np.concatenate((np.zeros(2000),audio[0].data.cpu().numpy())), rate=hparams.sampling_rate)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}